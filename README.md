# A regarder : 
* Section 3 GAN's Computer Vision A-Zâ„¢: https://www.udemy.com/computer-vision-a-z/learn/v4/t/lecture/8138282?start=0


# Creation and training of a DCGAN 

### Part 1 : Creating the DCGAN 

```python
# Defining the generator- Deconvolutional Network 

class G(nn.Model): 

	# Design of the network Generator 

	#Architecture 
	def __init__(self): 
	 	super(G,self).__init__()
	 	self.main=nn.Sequential(nn.ConvTransposed2d(100,512,4,1,0, bias=False), 
	 	#ConvTransposed2d(input_size, output_size, kernel, stride, padding)
	 	nn.BatchNorm2d(512), 
	 	#Batchnormed features map. 
	 	nn.Relu(True),
	 	nn.ConvTransposed2d(512,256,4,2,1, bias=False), 
	 	nn.BatchNorm2d(256), 
	 	nn.Relu(True),
	 	nn.ConvTransposed2d(256,128,4,2,1, bias=False), 
	 	nn.BatchNorm2d(128), 
	 	nn.Relu(True),
	 	nn.ConvTransposed2d(128,64,4,2,1, bias=False), 
	 	nn.BatchNorm2d(64), 
	 	nn.Relu(True),
	 	nn.ConvTransposed2d(64,3,4,2,1, bias=False) # 3 channels of the colour images
	 	nn.Tanh() # output between [-1,1] same standard of the image of the dataset 
	 	)

	# Propagation 
	def forward (self,input) # input~random noise 
	output=self.main(input)
	return output 

	 	
	#Creating the generator : create an object and weight initialization. 
	netG=G()
	netG.apply(weight_init) # def weight_init(m) 


#Defining the discriminator-Convolutional Network 

class D(nn.Model): 

	#Architecture 
	def __init__(self)
	super(D, self).__init__()
	self.main=nn.Sequential(
	nn.Conv2d(3,64,4,2,1, bias=False) # number of channels / output of the generator 
	nn.LeakyRelu(0.2, inplace=True)
	nn.Conv2d(64,128,4,2,1, bias=False)
	nn.BatchNorm2d(128),
	nn.LeakyRelu(0.2, inplace=True)
	nn.Conv2d(128,256,4,2,1, bias=False)
	nn.BatchNorm2d(256),
	nn.LeakyRelu(0.2, inplace=True)
	nn.Conv2d(256,512,4,2,1, bias=False)
	nn.BatchNorm2d(512),
	nn.LeakyRelu(0.2, inplace=True)
	nn.Conv2d(512,1,4,2,1, bias=False) # output is 1 False or True. 
	nn.Sigmoid() # ~False(0) or True(1) 
	)

	# Propagation 
	def forward(self,input)
	output=self.main(input) # input image generated by the generator 
	return output.view(-1) # flatten the output of the convolution 

	#Creating the discriminator : create an object and weight initialization. 
	netD=D()
	netD.apply(weight_init)
```

## Part 2 : Training the DCGANS 

```python
criterion=nn.BCELoss()
optimizerD=optimi.Adam(netD.parameters(),lr=0.0002, betas=(0.5,0.9999))
optimizerG=optimi.Adam(netG.parameters(),lr=0.0002, betas=(0.5,0.9999))

for epoch in range (25) : # 25 epochs 
	
	for i, data in enumerate(dataloader,0)   # mini-batches of the data 

	

	# 1st step : updating the weights of the descriminator 
	
	netD.zero_grad() 

	## Training the discriminator with real images of the dataset 
	real,_=data # (image,label so real (image) is the first element, _ ~no need of label)
	input=Variable(real) # torch Variable 
	target= Variable(torch.ones(input.size()[0]))
	# torch.ones : target is full of "one" because we need to tell the discriminator 
	#that the image are real.
	# the target need to have the input.size
	output=netD(input)
	errD_real = criterion(output,target)

	##Training the discriminator with fake images gerenrated by the generator 
	# input of the generator 
	noise=Variable(torch.randn(input.size()[0],100,1,1))
	fake=netC(noise) # generation of the fake images and update of the gradients
	target= Variable(torch.zeros(input.size()[0])) 
	# torch.zeros : target is full "zero" because we need to tell the discriminator 
	#that the images generated are fake
	output=netD(fake.detach()) # detach ~don't care the gradients. 
	errD_fake = criterion(output,target)

	## Backpropagating the Total Error 
	errorD=errD_real + errD_fake
	errorD.backward()
	optimizerD.step()


	# 2nd step : updating the weights of the generator 

	netG.zero_grad() 
	target= Variable(torch.ones(input.size()[0])) 
	# torch.ones force the generator to create real image 
	output=netD(fake) # this time we keep the gradients 
	errG= criterion(output,target)
	errG.backward()
	optimizerG.step()
  ```
